{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/j13mehul/dl-architecture-10-features-bert-embedding?scriptVersionId=143536186\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"background-color: powderblue; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">üèÅ Setting the stage üéå</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:08:34.241188Z","iopub.execute_input":"2023-09-19T14:08:34.241814Z","iopub.status.idle":"2023-09-19T14:09:46.429574Z","shell.execute_reply.started":"2023-09-19T14:08:34.241778Z","shell.execute_reply":"2023-09-19T14:09:46.428287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np \nimport pandas as pd\nimport string\nfrom collections import Counter\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error\n\nimport optuna\nimport lightgbm as lgb\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom torch import nn\nimport torch.optim as optim\nfrom transformers import DataCollatorWithPadding, AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup, Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:10:11.969444Z","iopub.execute_input":"2023-09-19T14:10:11.97014Z","iopub.status.idle":"2023-09-19T14:10:28.842492Z","shell.execute_reply.started":"2023-09-19T14:10:11.970105Z","shell.execute_reply":"2023-09-19T14:10:28.841454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train\nprompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nsummaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\ndf = prompts.merge(summaries, on = ['prompt_id'],how ='left')\n\n#Test\nprompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\nsummaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest = prompts_test.merge(summaries_test, on = ['prompt_id'],how ='left')","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:10:28.844369Z","iopub.execute_input":"2023-09-19T14:10:28.846403Z","iopub.status.idle":"2023-09-19T14:10:29.011791Z","shell.execute_reply.started":"2023-09-19T14:10:28.84636Z","shell.execute_reply":"2023-09-19T14:10:29.010694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #c4affa; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">üßπ Data Cleaning & Processing ‚öôÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"spell = Speller(lang='en')\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\n', ' ', text)\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndf['prompt_text'] = df['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['prompt_text'] = test['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:12:48.189406Z","iopub.execute_input":"2023-09-19T14:12:48.189815Z","iopub.status.idle":"2023-09-19T14:12:51.277653Z","shell.execute_reply.started":"2023-09-19T14:12:48.189783Z","shell.execute_reply":"2023-09-19T14:12:51.276634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #ea9bc4; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">  üßë‚Äçüî¨ Feature Engineering üë®‚Äçüî¨</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 0</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Deberta V3 predictions</h1></div>","metadata":{}},{"cell_type":"code","source":"model_name = \"/kaggle/input/deberta-v3-base/deberta-v3-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, problem_type=\"regression\")","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:12:51.279878Z","iopub.execute_input":"2023-09-19T14:12:51.280263Z","iopub.status.idle":"2023-09-19T14:12:58.998632Z","shell.execute_reply.started":"2023-09-19T14:12:51.28023Z","shell.execute_reply":"2023-09-19T14:12:58.997559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, has_labels=True):\n        self.df = df\n        self.prompt_titles = df[\"question\"].values.tolist()\n        self.texts = df[\"correct_text\"].values.tolist()\n        self.encoded_examples = tokenizer(\n            text=self.prompt_titles,\n            text_pair=self.texts,\n            truncation=True,\n            padding=True,\n            max_length=512,\n            return_tensors=\"pt\"\n        )\n        self.has_labels = has_labels\n        \n        if self.has_labels:\n            self.labels_list = df[[\"content\", \"wording\"]].values.tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        item = {\n            \"input_ids\": self.encoded_examples[\"input_ids\"][idx],\n            \"attention_mask\": self.encoded_examples[\"attention_mask\"][idx],\n            \"token_type_ids\": self.encoded_examples[\"token_type_ids\"][idx]\n        }\n        \n        if self.has_labels:\n            item[\"labels\"] = torch.tensor(self.labels_list[idx])\n        \n        return item","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:12:59.000185Z","iopub.execute_input":"2023-09-19T14:12:59.00059Z","iopub.status.idle":"2023-09-19T14:12:59.010723Z","shell.execute_reply.started":"2023-09-19T14:12:59.000553Z","shell.execute_reply":"2023-09-19T14:12:59.009661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_mcrmse(eval_pred):\n\n    predictions, labels = eval_pred\n    squared_errors = np.square(predictions - labels)\n    mean_squared_errors = np.mean(squared_errors, axis=0)\n    \n    rmse = np.sqrt(mean_squared_errors)\n    \n    mcrmse_value = np.mean(rmse)\n    \n    content_rmse = rmse[0]\n    wording_rmse = rmse[1]\n    \n    return {\n        \"mcrmse\": mcrmse_value,\n        \"content_rmse\": content_rmse,\n        \"wording_rmse\": wording_rmse\n    }","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:12:59.013652Z","iopub.execute_input":"2023-09-19T14:12:59.014412Z","iopub.status.idle":"2023-09-19T14:12:59.02552Z","shell.execute_reply.started":"2023-09-19T14:12:59.014377Z","shell.execute_reply":"2023-09-19T14:12:59.0245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\ndf['question'] = df[\"prompt_title\"] + \"\\n\" + df[\"prompt_question\"] + \"\\n\" + df[\"prompt_text\"]\ntest['question'] = test[\"prompt_title\"] + \"\\n\" + test[\"prompt_question\"] + \"\\n\" + test[\"prompt_text\"]\n\ndf_train, df_valid = train_test_split(df, test_size=0.2, random_state=2023)\n\ntrain_dataset = CustomDataset(df_train)\nvalid_dataset = CustomDataset(df_valid)\ntest_dataset  = CustomDataset(test, has_labels=False)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntraining_args = TrainingArguments(\n    output_dir=\"output\",             \n    per_device_train_batch_size=8,   \n    per_device_eval_batch_size=4,    \n    learning_rate=1e-3,            \n    lr_scheduler_type=\"linear\",      \n    warmup_ratio=0.01,               \n    num_train_epochs=3,              \n    save_strategy=\"epoch\",           \n    logging_strategy=\"epoch\",        \n    evaluation_strategy=\"epoch\",     \n    load_best_model_at_end=True,     \n    metric_for_best_model=\"mcrmse\",           \n    fp16=False,                      \n    report_to='none',\n    save_total_limit=1\n)\n\ntrainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_mcrmse,\n)\ntrainer.train()\n\ntrainer.save_model(\"best_model\")\n\ndf_train = df_train.reset_index(drop = True)\ndf_valid = df_valid.reset_index(drop = True)\n\npredictions_train = trainer.predict(train_dataset)\ndeberta_content = predictions_train.predictions[:, 0].tolist()\ndeberta_wording = predictions_train.predictions[:, 1].tolist()\n\ndf_train['deberta_content'] = deberta_content\ndf_train['deberta_wording'] = deberta_wording\n\npredictions_val = trainer.predict(valid_dataset)\ndeberta_content = predictions_val.predictions[:, 0].tolist()\ndeberta_wording = predictions_val.predictions[:, 1].tolist()\n\ndf_valid['deberta_content'] = deberta_content\ndf_valid['deberta_wording'] = deberta_wording\n\npredictions_test = trainer.predict(test_dataset)\ndeberta_content = predictions_test.predictions[:, 0].tolist()\ndeberta_wording = predictions_test.predictions[:, 1].tolist()\n\ntest['deberta_content'] = deberta_content\ntest['deberta_wording'] = deberta_wording","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:12:59.027322Z","iopub.execute_input":"2023-09-19T14:12:59.027781Z","iopub.status.idle":"2023-09-19T14:14:07.411792Z","shell.execute_reply.started":"2023-09-19T14:12:59.027718Z","shell.execute_reply":"2023-09-19T14:14:07.410863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_val = pd.concat([df_train[['prompt_id','student_id','deberta_content','deberta_wording']], \n                          df_valid[['prompt_id','student_id','deberta_content','deberta_wording']]], ignore_index=True)\n\ndf = df.merge(df_train_val, on = ['prompt_id','student_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:14:07.413413Z","iopub.execute_input":"2023-09-19T14:14:07.413856Z","iopub.status.idle":"2023-09-19T14:14:07.426418Z","shell.execute_reply.started":"2023-09-19T14:14:07.413821Z","shell.execute_reply":"2023-09-19T14:14:07.424959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_train_val, trainer, train_dataset, valid_dataset, test_dataset, data_collator, df_train, df_valid, predictions_train, predictions_val, predictions_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T14:14:07.428164Z","iopub.execute_input":"2023-09-19T14:14:07.428637Z","iopub.status.idle":"2023-09-19T14:14:07.832936Z","shell.execute_reply.started":"2023-09-19T14:14:07.428583Z","shell.execute_reply":"2023-09-19T14:14:07.826012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 1</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Ratio of No of words in Student's response vs context</h1></div>","metadata":{}},{"cell_type":"code","source":"def wordsRatio(context, response):\n    context = context.split()\n    response = response.split()\n    return len(response)/len(context)\n\ndf[\"word_count_ratio\"] = df.apply(lambda x: wordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"word_count_ratio\"] = test.apply(lambda x: wordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:19:52.957037Z","iopub.execute_input":"2023-09-19T07:19:52.958095Z","iopub.status.idle":"2023-09-19T07:19:52.97734Z","shell.execute_reply.started":"2023-09-19T07:19:52.958055Z","shell.execute_reply":"2023-09-19T07:19:52.97621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 2</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Number of spelling errors in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"def misspelledRatio(x):\n    spell = SpellChecker()\n    words = x.split()\n    misspelled = spell.unknown(words)\n    return len(misspelled)/len(words)\n\ndf[\"misspelled_ratio\"] = df['text'].apply(lambda x: misspelledRatio(x))  \ntest[\"misspelled_ratio\"] = test['text'].apply(lambda x: misspelledRatio(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:19:54.359972Z","iopub.execute_input":"2023-09-19T07:19:54.360337Z","iopub.status.idle":"2023-09-19T07:20:02.201536Z","shell.execute_reply.started":"2023-09-19T07:19:54.360307Z","shell.execute_reply":"2023-09-19T07:20:02.200408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 3</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Stop word Ratio in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\ndef StopwordsRatio(context, response):\n    length  = len(response.split())\n    response = \" \".join([i for i in response.split() if i in stop_words]) \n    return len(response)/length\n\ndf[\"stop_word_ratio\"] = df.apply(lambda x: StopwordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"stop_word_ratio\"] = test.apply(lambda x: StopwordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:02.203633Z","iopub.execute_input":"2023-09-19T07:20:02.203976Z","iopub.status.idle":"2023-09-19T07:20:02.239803Z","shell.execute_reply.started":"2023-09-19T07:20:02.203944Z","shell.execute_reply":"2023-09-19T07:20:02.238925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 4</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Count of same words in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"def sameWordsRatio(context, response):\n    context = \" \".join([i for i in context.split() if i not in stop_words]) \n    response = \" \".join([i for i in response.split() if i not in stop_words]) \n    return len(set(response).intersection(set(context)))/len(response)\n\ndf[\"same_word_ratio\"] = df.apply(lambda x: sameWordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"same_word_ratio\"] = test.apply(lambda x: sameWordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:02.241234Z","iopub.execute_input":"2023-09-19T07:20:02.241618Z","iopub.status.idle":"2023-09-19T07:20:02.384632Z","shell.execute_reply.started":"2023-09-19T07:20:02.241586Z","shell.execute_reply":"2023-09-19T07:20:02.383752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 5</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Average reading speed in words per minute </h1></div>","metadata":{}},{"cell_type":"code","source":"def readTime(x):\n    average_wpm = 200\n    word_count = len(x.split())\n    return word_count / average_wpm\n\ndf[\"read_time\"] = df['text'].apply(lambda x: readTime(x))  \ntest[\"read_time\"] = test['text'].apply(lambda x: readTime(x))  ","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:02.387237Z","iopub.execute_input":"2023-09-19T07:20:02.388748Z","iopub.status.idle":"2023-09-19T07:20:02.395796Z","shell.execute_reply.started":"2023-09-19T07:20:02.388713Z","shell.execute_reply":"2023-09-19T07:20:02.394866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 6</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Diversity of words in the Student's response </h1></div>","metadata":{}},{"cell_type":"code","source":"def diversityIndex(x):\n    words = x.split()\n    word_counts = Counter(words)\n    total_words = len(words)\n    return 1 - sum((count / total_words) ** 2 for count in word_counts.values())\n\ndf[\"diversity_index\"] = df['text'].apply(lambda x: diversityIndex(x))  \ntest[\"diversity_index\"] = test['text'].apply(lambda x: diversityIndex(x))  ","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:02.397257Z","iopub.execute_input":"2023-09-19T07:20:02.397618Z","iopub.status.idle":"2023-09-19T07:20:02.412277Z","shell.execute_reply.started":"2023-09-19T07:20:02.397586Z","shell.execute_reply":"2023-09-19T07:20:02.411366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 7</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> TF IDF to identify most frequent words in context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"def tfidfImportance(context, response):\n    top_n = 10\n\n    context = \" \".join([i for i in context.split() if i not in stop_words]) \n    response = \" \".join([i for i in response.split() if i not in stop_words]) \n    \n    corpus = [\n        context, response\n     ]\n\n    tfidf_unigram = TfidfVectorizer(ngram_range=(1, 1))\n    tfidf_unigram_matrix = tfidf_unigram.fit_transform(corpus)\n    unigram_feature_names = tfidf_unigram.get_feature_names_out()\n    dense_unigram_array = tfidf_unigram_matrix.toarray()\n    unigram_df = pd.DataFrame(data=dense_unigram_array, columns=unigram_feature_names)\n\n    top_unigrams = []\n    for index, row in unigram_df.iterrows():\n        top_unigrams.append(list(row.nlargest(top_n).index))\n\n    tfidf_bigram = TfidfVectorizer(ngram_range=(2, 2)) \n\n    tfidf_bigram_matrix = tfidf_bigram.fit_transform(corpus)\n    bigram_feature_names = tfidf_bigram.get_feature_names_out()\n    dense_bigram_array = tfidf_bigram_matrix.toarray()\n    bigram_df = pd.DataFrame(data=dense_bigram_array, columns=bigram_feature_names)\n\n    top_bigrams = []\n    for index, row in bigram_df.iterrows():\n        top_bigrams.append(list(row.nlargest(top_n).index))\n\n\n    return len(set(top_unigrams[0]).intersection(set(top_unigrams[1])))/top_n, len(set(top_bigrams[0]).intersection(set(top_bigrams[1])))/top_n\n\ndf[['top_unigrams_ratio','top_bigrams_ratio']]= df.apply(lambda x: tfidfImportance(x['prompt_text'], x['correct_text']), axis=1, result_type ='expand')\ntest[['top_unigrams_ratio','top_bigrams_ratio']]= test.apply(lambda x: tfidfImportance(x['prompt_text'], x['correct_text']), axis=1, result_type ='expand')","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:02.413803Z","iopub.execute_input":"2023-09-19T07:20:02.414141Z","iopub.status.idle":"2023-09-19T07:20:03.600817Z","shell.execute_reply.started":"2023-09-19T07:20:02.414109Z","shell.execute_reply":"2023-09-19T07:20:03.59984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 8</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Cosine similarity of context and response using TD IDF vectors</h1></div>","metadata":{}},{"cell_type":"code","source":"def tdidfSimilarity(context, response):\n    vectorizer = TfidfVectorizer()\n    vectors = vectorizer.fit_transform([context, response])\n    return cosine_similarity(vectors[0:1], vectors[1:2])[0][0] \n\ndf['tfidf_similarity']= df.apply(lambda x: tdidfSimilarity(x['prompt_text'], x['correct_text']), axis=1)\ntest['tfidf_similarity']= test.apply(lambda x: tdidfSimilarity(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:03.602321Z","iopub.execute_input":"2023-09-19T07:20:03.602699Z","iopub.status.idle":"2023-09-19T07:20:04.060631Z","shell.execute_reply.started":"2023-09-19T07:20:03.602665Z","shell.execute_reply":"2023-09-19T07:20:04.059643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 9</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> N Grams Co occurence context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"def tokenize(sentence):\n    sentence = re.sub(r'[^\\w\\s]', '', sentence.lower())\n    tokens = sentence.split()\n    return tokens\n\ndef generate_ngrams(tokens, n):\n    ngrams = []\n    for i in range(len(tokens) - n + 1):\n        ngram = tuple(tokens[i:i + n])\n        ngrams.append(ngram)\n    return ngrams\n\n\ndef cooccurrenceRatio(context, response, n_gram_size = 2):\n    tokens1 = tokenize(context)\n    tokens2 = tokenize(response)\n\n    ngrams1 = generate_ngrams(tokens1, n_gram_size)\n    ngrams2 = generate_ngrams(tokens2, n_gram_size)\n\n    co_occurrence_count = len(set(ngrams1) & set(ngrams2))\n    \n    return co_occurrence_count/(min(len(ngrams1),len(ngrams2))+1)\n\ndf['bi_gram_ratio'] = df.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest['bi_gram_ratio'] = test.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\n\ndf['tri_gram_ratio'] = df.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text'], n_gram_size = 3), axis=1)\ntest['tri_gram_ratio'] = test.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text'],n_gram_size = 3 ), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:04.062073Z","iopub.execute_input":"2023-09-19T07:20:04.062457Z","iopub.status.idle":"2023-09-19T07:20:04.189407Z","shell.execute_reply.started":"2023-09-19T07:20:04.06242Z","shell.execute_reply":"2023-09-19T07:20:04.188553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 10</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Check punctuation in Student's response </h1></div>","metadata":{}},{"cell_type":"code","source":"def checkPunctuations(x):\n    punctuation_count = 0\n\n    for char in x:\n        if char in string.punctuation:\n            punctuation_count += 1\n    return punctuation_count/len(x.split())\n\ndf[\"punctuation_ratio\"] = df['text'].apply(lambda x: checkPunctuations(x))\ntest[\"punctuation_ratio\"] = test['text'].apply(lambda x: checkPunctuations(x)) ","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:04.190834Z","iopub.execute_input":"2023-09-19T07:20:04.191189Z","iopub.status.idle":"2023-09-19T07:20:04.201877Z","shell.execute_reply.started":"2023-09-19T07:20:04.191157Z","shell.execute_reply":"2023-09-19T07:20:04.200882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 11</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Identifying Co occurences of NER in context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ndef nerCooccurrenceRatio(context, response, n_gram_size = 2):\n    \n    doc1 = nlp(context)\n    doc2 = nlp(response)\n    \n    entities1 = {ent.text for ent in doc1.ents}\n    entities2 = {ent.text for ent in doc2.ents}\n    \n    overlap_entities = entities1.intersection(entities2)\n    return len(overlap_entities)/(min(len(entities1),len(entities2))+1)\n\n\ndf['nercooccurrence_ratio'] = df.apply(lambda x: nerCooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest['nercooccurrence_ratio'] = test.apply(lambda x: nerCooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:04.207055Z","iopub.execute_input":"2023-09-19T07:20:04.207413Z","iopub.status.idle":"2023-09-19T07:20:17.137325Z","shell.execute_reply.started":"2023-09-19T07:20:04.207381Z","shell.execute_reply":"2023-09-19T07:20:17.136207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #b6d7a8; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üî¨ EDA ‚öóÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,2, 1)  \nsns.histplot(x=df['content'], bins=50, kde=True, color='#ed8240')\nplt.title(f\"Histogram of content\")\n\nplt.subplot(1,2, 2)  \nsns.histplot(x=df['wording'], bins=50, kde=True, color='#c540ed')\nplt.title(f\"Histogram of wording\")\n\nplt.tight_layout() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:17.13919Z","iopub.execute_input":"2023-09-19T07:20:17.139643Z","iopub.status.idle":"2023-09-19T07:20:18.054121Z","shell.execute_reply.started":"2023-09-19T07:20:17.139602Z","shell.execute_reply":"2023-09-19T07:20:18.053174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [\n    'deberta_content',\n    'deberta_wording',\n    'word_count_ratio', \n    'misspelled_ratio', \n    'stop_word_ratio',\n    'same_word_ratio', \n    'read_time', \n    'diversity_index', \n    'top_unigrams_ratio',\n    'top_bigrams_ratio',\n    'tfidf_similarity',\n    'punctuation_ratio', \n    'bi_gram_ratio',\n    'tri_gram_ratio', \n    'nercooccurrence_ratio'\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:18.055431Z","iopub.execute_input":"2023-09-19T07:20:18.05636Z","iopub.status.idle":"2023-09-19T07:20:18.061749Z","shell.execute_reply.started":"2023-09-19T07:20:18.056324Z","shell.execute_reply":"2023-09-19T07:20:18.060762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cols = ['content','wording'] + cols\nplt.figure(figsize=(15, 7))\nsns.heatmap(df[all_cols].corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:18.062972Z","iopub.execute_input":"2023-09-19T07:20:18.063772Z","iopub.status.idle":"2023-09-19T07:20:19.39533Z","shell.execute_reply.started":"2023-09-19T07:20:18.063738Z","shell.execute_reply":"2023-09-19T07:20:19.394461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cols:\n    print(f'Plots for {col}')\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1,3, 1)  \n    sns.scatterplot(x=df[col], y=df['content'], color='#4082ed')\n    plt.title(\"Scatterplot with content\")\n\n    plt.subplot(1, 3, 2)  \n    sns.scatterplot(x=df[col], y=df['wording'], color='#40b9ed')\n    plt.title(\"Scatterplot with wording\")\n\n    plt.subplot(1, 3, 3)  \n    sns.histplot(x=df[col], bins=50, kde=True, color='#40d3ed')\n    plt.title(f\"Histogram of {col}\")\n\n    plt.tight_layout() \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:20:19.396383Z","iopub.execute_input":"2023-09-19T07:20:19.396712Z","iopub.status.idle":"2023-09-19T07:20:32.652769Z","shell.execute_reply.started":"2023-09-19T07:20:19.396682Z","shell.execute_reply":"2023-09-19T07:20:32.651834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color: #8dc1e9; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üê• Bert Embedding üê•</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"/kaggle/input/huggingface-bert/bert-base-uncased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\nmax_chunk_length = 512\n\n\ndef get_embeddings_for_sent(sent):\n    input_ids = tokenizer(sent, padding=True, truncation=True, max_length=max_chunk_length, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs = model(**input_ids)\n    cls_embedding = outputs.last_hidden_state[:, 0, :] \n    return cls_embedding\n\n\ndef get_embeddings_for_para(document):\n    chunks = [document[i:i + max_chunk_length] for i in range(0, len(document), max_chunk_length)]\n    chunk_embeddings = []\n    for chunk in chunks:\n        input_ids = tokenizer(chunk, padding=True, truncation=True, max_length=max_chunk_length, return_tensors=\"pt\")\n        with torch.no_grad():\n            outputs = model(**input_ids)\n            cls_embedding = outputs.last_hidden_state[:, 0, :]\n        chunk_embeddings.append(cls_embedding)\n        final_embedding = torch.mean(torch.stack(chunk_embeddings), dim=0)\n        return final_embedding","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:32.316953Z","iopub.execute_input":"2023-09-19T07:21:32.317322Z","iopub.status.idle":"2023-09-19T07:21:37.755283Z","shell.execute_reply.started":"2023-09-19T07:21:32.317293Z","shell.execute_reply":"2023-09-19T07:21:37.75425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of prompt_question \nprmt_data = df[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\nprmt_test = test[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\n\nprmt_data[\"text_emb\"] = prmt_data['prompt_question'].apply(lambda x: get_embeddings_for_sent(x))  \nprmt_data[\"flattened_embedding\"] = prmt_data[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_df = pd.DataFrame(prmt_data[\"flattened_embedding\"].to_list())\nemb_df = pd.concat([prmt_data[['prompt_id']], emb_df],axis = 1)\nemb_df = df[['prompt_id']].merge(emb_df, on = 'prompt_id', how = 'left').drop(['prompt_id'], axis= 1)\n\nprmt_test[\"text_emb\"] = prmt_test['prompt_question'].apply(lambda x: get_embeddings_for_sent(x))  \nprmt_test[\"flattened_embedding\"] = prmt_test[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_test = pd.DataFrame(prmt_test[\"flattened_embedding\"].to_list())\nemb_test = pd.concat([prmt_test[['prompt_id']], emb_test],axis = 1)\nemb_test = test[['prompt_id']].merge(emb_test, on = 'prompt_id', how = 'left').drop(['prompt_id'],axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:37.757351Z","iopub.execute_input":"2023-09-19T07:21:37.757746Z","iopub.status.idle":"2023-09-19T07:21:38.298312Z","shell.execute_reply.started":"2023-09-19T07:21:37.75771Z","shell.execute_reply":"2023-09-19T07:21:38.297276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of prompt_text\nprmt_data = df[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\nprmt_test = test[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\n\nprmt_data[\"text_emb\"] = prmt_data['prompt_text'].apply(lambda x: get_embeddings_for_para(x))  \nprmt_data[\"flattened_embedding\"] = prmt_data[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_cntxt_df = pd.DataFrame(prmt_data[\"flattened_embedding\"].to_list())\nemb_cntxt_df = pd.concat([prmt_data[['prompt_id']], emb_cntxt_df],axis = 1)\nemb_cntxt_df = df[['prompt_id']].merge(emb_cntxt_df, on = 'prompt_id', how = 'left').drop(['prompt_id'], axis= 1)\n\nprmt_test[\"text_emb\"] = prmt_test['prompt_text'].apply(lambda x: get_embeddings_for_para(x))  \nprmt_test[\"flattened_embedding\"] = prmt_test[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_cntxt_test = pd.DataFrame(prmt_test[\"flattened_embedding\"].to_list())\nemb_cntxt_test = pd.concat([prmt_test[['prompt_id']], emb_cntxt_test],axis = 1)\nemb_cntxt_test = test[['prompt_id']].merge(emb_cntxt_test, on = 'prompt_id', how = 'left').drop(['prompt_id'],axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:38.300102Z","iopub.execute_input":"2023-09-19T07:21:38.300539Z","iopub.status.idle":"2023-09-19T07:21:38.775866Z","shell.execute_reply.started":"2023-09-19T07:21:38.300469Z","shell.execute_reply":"2023-09-19T07:21:38.774824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of response\ndf[\"correct_text_emb\"] = df['correct_text'].apply(lambda x: get_embeddings_for_sent(x))  \ndf[\"correct_text_flattened_embedding\"] = df[\"correct_text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_corrt_df = pd.DataFrame(df[\"correct_text_flattened_embedding\"].to_list())\n\ntest[\"correct_text_emb\"] = test['correct_text'].apply(lambda x: get_embeddings_for_sent(x))  \ntest[\"correct_text_flattened_embedding\"] = test[\"correct_text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_corrt_test = pd.DataFrame(test[\"correct_text_flattened_embedding\"].to_list())","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:38.778412Z","iopub.execute_input":"2023-09-19T07:21:38.778822Z","iopub.status.idle":"2023-09-19T07:21:58.714822Z","shell.execute_reply.started":"2023-09-19T07:21:38.778786Z","shell.execute_reply":"2023-09-19T07:21:58.713843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df[cols]\ntest_score = test[cols]\nY = df[['content','wording']]","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.71626Z","iopub.execute_input":"2023-09-19T07:21:58.716633Z","iopub.status.idle":"2023-09-19T07:21:58.725241Z","shell.execute_reply.started":"2023-09-19T07:21:58.716599Z","shell.execute_reply":"2023-09-19T07:21:58.72408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_similarity = []\nfor index, row in emb_cntxt_df.iterrows():\n    x = [row.to_numpy()]\n    y = [emb_corrt_df.iloc[index,:].to_numpy()]\n    \n    x = x / np.linalg.norm(x, axis=1, keepdims=True)\n    y = y / np.linalg.norm(y, axis=1, keepdims=True)\n    list_similarity.append(cosine_similarity(x, y)[0][0])","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.726783Z","iopub.execute_input":"2023-09-19T07:21:58.727331Z","iopub.status.idle":"2023-09-19T07:21:58.80328Z","shell.execute_reply.started":"2023-09-19T07:21:58.727298Z","shell.execute_reply":"2023-09-19T07:21:58.802432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_similarity_test = []\nfor index, row in emb_cntxt_test.iterrows():\n    x = [row.to_numpy()]\n    y = [emb_corrt_test.iloc[index,:].to_numpy()]\n    \n    x = x / np.linalg.norm(x, axis=1, keepdims=True)\n    y = y / np.linalg.norm(y, axis=1, keepdims=True)\n    list_similarity_test.append(cosine_similarity(x, y)[0][0])","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.804431Z","iopub.execute_input":"2023-09-19T07:21:58.805003Z","iopub.status.idle":"2023-09-19T07:21:58.815874Z","shell.execute_reply.started":"2023-09-19T07:21:58.80497Z","shell.execute_reply":"2023-09-19T07:21:58.814988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cosine_similarity'] =  list_similarity\ntest_score['cosine_similarity'] =  list_similarity_test","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.817142Z","iopub.execute_input":"2023-09-19T07:21:58.817727Z","iopub.status.idle":"2023-09-19T07:21:58.830542Z","shell.execute_reply.started":"2023-09-19T07:21:58.817695Z","shell.execute_reply":"2023-09-19T07:21:58.829569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val = train_test_split(train, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.834639Z","iopub.execute_input":"2023-09-19T07:21:58.835249Z","iopub.status.idle":"2023-09-19T07:21:58.843185Z","shell.execute_reply.started":"2023-09-19T07:21:58.835217Z","shell.execute_reply":"2023-09-19T07:21:58.84223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_cntxt_train = emb_cntxt_df.filter(X_train.index, axis=0)\nemb_cntxt_val = emb_cntxt_df.filter(X_val.index, axis=0)\n\nemb_corrt_train = emb_corrt_df.filter(X_train.index, axis=0)\nemb_corrt_val = emb_corrt_df.filter(X_val.index, axis=0)\n\nemb_train = emb_df.filter(X_train.index, axis=0)\nemb_val = emb_df.filter(X_val.index, axis=0)\n\nY_train = Y.filter(X_train.index, axis=0)\nY_val = Y.filter(X_val.index, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.844192Z","iopub.execute_input":"2023-09-19T07:21:58.845666Z","iopub.status.idle":"2023-09-19T07:21:58.858658Z","shell.execute_reply.started":"2023-09-19T07:21:58.845633Z","shell.execute_reply":"2023-09-19T07:21:58.857453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for question\nnum_components = 3\nq_label = ['q'+ str(i) for i in range(num_components)]\npca = PCA(n_components=num_components)\n\nemb_train_pca = pca.fit_transform(emb_train)\nemb_val_pca = pca.transform(emb_val)\nemb_test_pca = pca.transform(emb_test)\n\nprincipal_components = pca.components_\nexplained_variance_ratio = pca.explained_variance_ratio_\nprint(\"Explained Variance Ratio:\", sum(explained_variance_ratio))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.860393Z","iopub.execute_input":"2023-09-19T07:21:58.861102Z","iopub.status.idle":"2023-09-19T07:21:58.980115Z","shell.execute_reply.started":"2023-09-19T07:21:58.861068Z","shell.execute_reply":"2023-09-19T07:21:58.978937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for response\nnum_components = 10\nr_label = ['r'+ str(i) for i in range(num_components)]\npca = PCA(n_components=num_components)\n\nemb_cntxt_train_pca = pca.fit_transform(emb_cntxt_train)\nemb_cntxt_val_pca = pca.transform(emb_cntxt_val)\nemb_cntxt_test_pca = pca.transform(emb_cntxt_test)\n\nprincipal_components = pca.components_\nexplained_variance_ratio = pca.explained_variance_ratio_\nprint(\"Explained Variance Ratio:\", sum(explained_variance_ratio))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:58.9814Z","iopub.execute_input":"2023-09-19T07:21:58.981735Z","iopub.status.idle":"2023-09-19T07:21:59.127412Z","shell.execute_reply.started":"2023-09-19T07:21:58.981703Z","shell.execute_reply":"2023-09-19T07:21:59.126327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for context\nnum_components = 10\nc_label = ['c'+ str(i) for i in range(num_components)]\n\npca = PCA(n_components=num_components)\n\nemb_corrt_train_pca = pca.fit_transform(emb_corrt_train)\nemb_corrt_val_pca = pca.transform(emb_corrt_val)\nemb_corrt_test_pca = pca.transform(emb_corrt_test)\n\nprincipal_components = pca.components_\nexplained_variance_ratio = pca.explained_variance_ratio_\nprint(\"Explained Variance Ratio:\", sum(explained_variance_ratio))","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.133471Z","iopub.execute_input":"2023-09-19T07:21:59.137336Z","iopub.status.idle":"2023-09-19T07:21:59.227186Z","shell.execute_reply.started":"2023-09-19T07:21:59.13729Z","shell.execute_reply":"2023-09-19T07:21:59.226086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_cols = list(X_train.columns) + q_label + r_label + c_label","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.233209Z","iopub.execute_input":"2023-09-19T07:21:59.237039Z","iopub.status.idle":"2023-09-19T07:21:59.247277Z","shell.execute_reply.started":"2023-09-19T07:21:59.236996Z","shell.execute_reply":"2023-09-19T07:21:59.245975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reset_index(drop = True)\nX_val = X_val.reset_index(drop = True)\ntest_score = test_score.reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.254146Z","iopub.execute_input":"2023-09-19T07:21:59.25788Z","iopub.status.idle":"2023-09-19T07:21:59.274069Z","shell.execute_reply.started":"2023-09-19T07:21:59.257833Z","shell.execute_reply":"2023-09-19T07:21:59.272953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_gbm = pd.concat([X_train, pd.DataFrame(emb_train_pca), pd.DataFrame(emb_cntxt_train_pca), pd.DataFrame(emb_corrt_train_pca)],axis = 1)\nX_val_gbm = pd.concat([X_val, pd.DataFrame(emb_val_pca), pd.DataFrame(emb_cntxt_val_pca), pd.DataFrame(emb_corrt_val_pca)],axis = 1)\nX_test_gbm = pd.concat([test_score, pd.DataFrame(emb_test_pca), pd.DataFrame(emb_cntxt_test_pca), pd.DataFrame(emb_corrt_test_pca)],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.280984Z","iopub.execute_input":"2023-09-19T07:21:59.284929Z","iopub.status.idle":"2023-09-19T07:21:59.305956Z","shell.execute_reply.started":"2023-09-19T07:21:59.284883Z","shell.execute_reply":"2023-09-19T07:21:59.304932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_gbm.columns = feat_cols\nX_val_gbm.columns = feat_cols\nX_test_gbm.columns = feat_cols","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.30819Z","iopub.execute_input":"2023-09-19T07:21:59.308843Z","iopub.status.idle":"2023-09-19T07:21:59.314582Z","shell.execute_reply.started":"2023-09-19T07:21:59.30881Z","shell.execute_reply":"2023-09-19T07:21:59.313726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM\n\nimport logging\nnull_handler = logging.NullHandler()\noptuna.logging.get_logger(\"optuna\").addHandler(null_handler)\nn_trials = 50\n\ndef objective(trial):\n    params = {\n        'objective': 'regression',\n        'metric': 'rmse',\n        'boosting_type': 'gbdt',\n        'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.7, 0.99),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.7, 0.99),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.01, 10),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.01, 10),\n        'verbose' : -1\n    }\n    \n    train_data = lgb.Dataset(X_train_gbm, label=Y_train[Y])\n    valid_data = lgb.Dataset(X_val_gbm, label=Y_val[Y], reference=train_data)\n    \n    model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], num_boost_round=10000, early_stopping_rounds=20, verbose_eval=False)\n    \n    valid_preds = model.predict(X_val_gbm)\n    rmse = np.sqrt(mean_squared_error(Y_val[Y], valid_preds))\n    \n    return rmse\n\n\nprint('Train for content')\nY = 'content'\nstudy1 = optuna.create_study(direction='minimize')\nstudy1.optimize(objective, n_trials=n_trials)\n\nbest_trial = study1.best_trial\nprint(\"Best RMSE: {:.4f}\".format(best_trial.value))\nprint(\"Best Params:\", best_trial.params)\n\n\nbest_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': best_trial.params['num_leaves'],  \n    'learning_rate': best_trial.params['learning_rate'],\n    'feature_fraction': best_trial.params['feature_fraction'],\n    'bagging_fraction': best_trial.params['bagging_fraction'],\n    'bagging_freq': best_trial.params['bagging_freq'],\n    'min_child_samples': best_trial.params['min_child_samples'],\n    'lambda_l1': best_trial.params['lambda_l1'],\n    'lambda_l2': best_trial.params['lambda_l2'],\n    'verbose' : -1\n}\n\n\ntrain_data = lgb.Dataset(X_train_gbm, label=Y_train[Y])\nbest_model = lgb.train(best_params, train_data, num_boost_round=1000)\ncontent_list = best_model.predict(X_test_gbm)\n\nprint('Train for wording')\nY = 'wording'\nstudy2 = optuna.create_study(direction='minimize')\nstudy2.optimize(objective, n_trials=n_trials)\n\nbest_trial = study2.best_trial\nprint(\"Best RMSE: {:.4f}\".format(best_trial.value))\nprint(\"Best Params:\", best_trial.params)\n\nbest_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': best_trial.params['num_leaves'],  \n    'learning_rate': best_trial.params['learning_rate'],\n    'feature_fraction': best_trial.params['feature_fraction'],\n    'bagging_fraction': best_trial.params['bagging_fraction'],\n    'bagging_freq': best_trial.params['bagging_freq'],\n    'min_child_samples': best_trial.params['min_child_samples'],\n    'lambda_l1': best_trial.params['lambda_l1'],\n    'lambda_l2': best_trial.params['lambda_l2'],\n    'verbose' : -1\n}\n\n\ntrain_data = lgb.Dataset(X_train_gbm, label=Y_train[Y])\nbest_model = lgb.train(best_params, train_data, num_boost_round=1000)\nwording_list = best_model.predict(X_test_gbm)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:21:59.315806Z","iopub.execute_input":"2023-09-19T07:21:59.31637Z","iopub.status.idle":"2023-09-19T07:22:10.709069Z","shell.execute_reply.started":"2023-09-19T07:21:59.316338Z","shell.execute_reply":"2023-09-19T07:22:10.708047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_side_features = len(X_train.columns)\n# hidden_dim1 = int(num_side_features/2)\n# num_emb= 768","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.710458Z","iopub.execute_input":"2023-09-19T07:22:10.710921Z","iopub.status.idle":"2023-09-19T07:22:10.715607Z","shell.execute_reply.started":"2023-09-19T07:22:10.710884Z","shell.execute_reply":"2023-09-19T07:22:10.714543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 32\n\n# question_inputs_train = torch.from_numpy(emb_cntxt_train.to_numpy())\n# context_inputs_train = torch.from_numpy(emb_train.to_numpy())\n# response_inputs_train = torch.from_numpy(emb_corrt_train.to_numpy())\n# side_feat_train = torch.from_numpy(X_train.to_numpy().astype(np.float32))\n# Y_train = torch.from_numpy(Y_train.to_numpy())\n\n# question_inputs_val = torch.from_numpy(emb_cntxt_val.to_numpy())\n# context_inputs_val = torch.from_numpy(emb_val.to_numpy())\n# response_inputs_val = torch.from_numpy(emb_corrt_val.to_numpy())\n# side_feat_val = torch.from_numpy(X_val.to_numpy().astype(np.float32))\n# Y_val = torch.from_numpy(Y_val.to_numpy())\n\n# question_inputs_test = torch.from_numpy(emb_cntxt_test.to_numpy())\n# context_inputs_test = torch.from_numpy(emb_test.to_numpy())\n# response_inputs_test = torch.from_numpy(emb_corrt_test.to_numpy())\n# side_feat_test = torch.from_numpy(test_score.to_numpy().astype(np.float32))\n\n# dataset_tensor_train = TensorDataset(question_inputs_train, context_inputs_train, response_inputs_train, side_feat_train, Y_train)\n# dataset_tensor_val = TensorDataset(question_inputs_val, context_inputs_val, response_inputs_val, side_feat_val, Y_val)\n\n# train_loader = DataLoader(dataset_tensor_train, batch_size, shuffle=False)  \n# val_loader = DataLoader(dataset_tensor_val, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.717143Z","iopub.execute_input":"2023-09-19T07:22:10.717475Z","iopub.status.idle":"2023-09-19T07:22:10.728358Z","shell.execute_reply.started":"2023-09-19T07:22:10.717443Z","shell.execute_reply":"2023-09-19T07:22:10.727419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #ffe599; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üè≠ Deep learning Architecture üèóÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"# # Define the deep learning model\n# class BertDotProductModel(nn.Module):\n#     def __init__(self, num_emb, num_side_features, hidden_dim1):\n#         super(BertDotProductModel, self).__init__()\n\n#         self.side_feature_layer = nn.Linear(num_side_features, hidden_dim1)  \n        \n#         self.fc1 = nn.Linear((num_emb * 2 + hidden_dim1 + 1), num_emb)\n#         self.fc2 = nn.Linear(768, 512) \n#         self.fc3 = nn.Linear(512, 512) \n#         self.fc4 = nn.Linear(512, 256) \n#         self.fc5 = nn.Linear(256, 128) \n#         self.fc6 = nn.Linear(128, 64)\n#         self.fc7 = nn.Linear(64, 2) \n#         self.relu = torch.nn.ReLU()\n\n#     def forward(self, question, context, response, side_features):\n\n#         dot_product = torch.sum(context * response, dim=1)\n#         side_features = self.side_feature_layer(side_features)\n#         residual_context = torch.sub(question, context)\n#         residual_response = torch.sub(question, response)\n#         concat_features = torch.cat((dot_product.unsqueeze(1), residual_context, residual_response, side_features), dim=1)\n\n#         fc_output = self.relu(concat_features)\n#         fc_output = self.fc1(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc2(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc3(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc4(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc5(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc6(fc_output)\n#         fc_output = self.relu(fc_output)\n#         fc_output = self.fc7(fc_output)\n        \n#         return fc_output","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.731348Z","iopub.execute_input":"2023-09-19T07:22:10.731652Z","iopub.status.idle":"2023-09-19T07:22:10.744333Z","shell.execute_reply.started":"2023-09-19T07:22:10.731617Z","shell.execute_reply":"2023-09-19T07:22:10.743301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = BertDotProductModel(num_emb, num_side_features, hidden_dim1)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.745854Z","iopub.execute_input":"2023-09-19T07:22:10.74623Z","iopub.status.idle":"2023-09-19T07:22:10.759159Z","shell.execute_reply.started":"2023-09-19T07:22:10.746197Z","shell.execute_reply":"2023-09-19T07:22:10.758237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training_loss = []\n# validation_loss = []\n\n# criterion = nn.MSELoss()\n\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\n# num_epochs = 20\n\n# for epoch in range(num_epochs):\n#     model.train()\n#     total_loss = 0.0\n\n#     for question, context, response, side_features, target in train_loader:\n#         optimizer.zero_grad()\n#         outputs = model(question, context, response, side_features)  \n    \n#         target = target.to(torch.float)\n\n#         loss1 = torch.sqrt(criterion(outputs[:, 0].squeeze(), target[:,0]))\n#         loss2 = torch.sqrt(criterion(outputs[:, 1].squeeze(), target[:,1])) \n        \n#         loss = loss1 + loss2\n#         total_loss += loss.item()\n        \n#         loss.backward()\n#         optimizer.step()\n        \n#     training_loss.append(total_loss / len(train_loader))\n\n#     model.eval()\n#     valid_loss = 0.0\n\n#     with torch.no_grad():\n#         for question, context, response, side_features, target in val_loader:\n#             outputs = model(question, context, response, side_features)\n#             loss1 = torch.sqrt(criterion(outputs[:, 0].squeeze(), target[:,0])) \n#             loss2 = torch.sqrt(criterion(outputs[:, 1].squeeze(), target[:,1])) \n            \n#             loss = loss1 + loss2 \n            \n#             valid_loss += loss.item()\n            \n#     validation_loss.append(valid_loss / len(val_loader))\n\n#     scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.760239Z","iopub.execute_input":"2023-09-19T07:22:10.760599Z","iopub.status.idle":"2023-09-19T07:22:10.77171Z","shell.execute_reply.started":"2023-09-19T07:22:10.760547Z","shell.execute_reply":"2023-09-19T07:22:10.77081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.lineplot(x=[i for i in range(num_epochs)], y=training_loss)\n# sns.lineplot(x=[i for i in range(num_epochs)], y=validation_loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.776581Z","iopub.execute_input":"2023-09-19T07:22:10.77761Z","iopub.status.idle":"2023-09-19T07:22:10.785477Z","shell.execute_reply.started":"2023-09-19T07:22:10.777578Z","shell.execute_reply":"2023-09-19T07:22:10.784545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.eval()\n\n# with torch.no_grad():\n#     outputs = model(question_inputs_test, context_inputs_test, response_inputs_test, side_feat_test)\n\n# outputs = outputs.numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.786459Z","iopub.execute_input":"2023-09-19T07:22:10.786774Z","iopub.status.idle":"2023-09-19T07:22:10.796303Z","shell.execute_reply.started":"2023-09-19T07:22:10.786744Z","shell.execute_reply":"2023-09-19T07:22:10.795358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# content_list = outputs[:, 0].tolist()\n# wording_list = outputs[:, 1].tolist()\n\nsubmission = test[['student_id']]\nsubmission['content'] = content_list\nsubmission['wording'] = wording_list\n\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-19T07:22:10.799064Z","iopub.execute_input":"2023-09-19T07:22:10.799866Z","iopub.status.idle":"2023-09-19T07:22:10.82063Z","shell.execute_reply.started":"2023-09-19T07:22:10.799824Z","shell.execute_reply":"2023-09-19T07:22:10.819366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #bcbcbc; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> If you find it useful, please upvote for my efforts ‚¨ÜÔ∏è </h1>\n</div>","metadata":{}}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color: powderblue; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">üèÅ Setting the stage üéå</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\"","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:01:57.691550Z","iopub.execute_input":"2023-09-14T13:01:57.692422Z","iopub.status.idle":"2023-09-14T13:03:02.537388Z","shell.execute_reply.started":"2023-09-14T13:01:57.692374Z","shell.execute_reply":"2023-09-14T13:03:02.536009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\nimport numpy as np \nimport pandas as pd\nimport string\nfrom collections import Counter\nimport re\nimport spacy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom autocorrect import Speller\nfrom spellchecker import SpellChecker\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nfrom torch import nn\nimport torch.optim as optim\nfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:02.540245Z","iopub.execute_input":"2023-09-14T13:03:02.541172Z","iopub.status.idle":"2023-09-14T13:03:02.549585Z","shell.execute_reply.started":"2023-09-14T13:03:02.541121Z","shell.execute_reply":"2023-09-14T13:03:02.548435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train\nprompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nsummaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\ndf = prompts.merge(summaries, on = ['prompt_id'],how ='left')\n\n#Test\nprompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\nsummaries_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\ntest = prompts_test.merge(summaries_test, on = ['prompt_id'],how ='left')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:02.551115Z","iopub.execute_input":"2023-09-14T13:03:02.551557Z","iopub.status.idle":"2023-09-14T13:03:02.649093Z","shell.execute_reply.started":"2023-09-14T13:03:02.551517Z","shell.execute_reply":"2023-09-14T13:03:02.648063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:02.662028Z","iopub.execute_input":"2023-09-14T13:03:02.662476Z","iopub.status.idle":"2023-09-14T13:03:02.683882Z","shell.execute_reply.started":"2023-09-14T13:03:02.662438Z","shell.execute_reply":"2023-09-14T13:03:02.682696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #c4affa; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">üßπ Data Cleaning & Processing ‚öôÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"spell = Speller(lang='en')\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\n', ' ', text)\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n\n\ndf['correct_text'] = df['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['correct_text'] = test['text'].apply(lambda x: \"\".join([spell(i) for i in x]))\n\ndf['prompt_text'] = df['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))\ntest['prompt_text'] = test['prompt_text'].apply(lambda x: \"\".join([spell(i) for i in x]))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:02.685178Z","iopub.execute_input":"2023-09-14T13:03:02.685536Z","iopub.status.idle":"2023-09-14T13:03:03.252116Z","shell.execute_reply.started":"2023-09-14T13:03:02.685498Z","shell.execute_reply":"2023-09-14T13:03:03.251293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #ea9bc4; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\">  üßë‚Äçüî¨ Feature Engineering üë®‚Äçüî¨</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 1</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Ratio of No of words in Student's response vs context</h1></div>","metadata":{}},{"cell_type":"code","source":"def wordsRatio(context, response):\n    context = context.split()\n    response = response.split()\n    return len(response)/len(context)\n\ndf[\"word_count_ratio\"] = df.apply(lambda x: wordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"word_count_ratio\"] = test.apply(lambda x: wordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:03.253291Z","iopub.execute_input":"2023-09-14T13:03:03.254631Z","iopub.status.idle":"2023-09-14T13:03:03.266804Z","shell.execute_reply.started":"2023-09-14T13:03:03.254583Z","shell.execute_reply":"2023-09-14T13:03:03.265556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 2</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Number of spelling errors in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"def misspelledRatio(x):\n    spell = SpellChecker()\n    words = x.split()\n    misspelled = spell.unknown(words)\n    return len(misspelled)/len(words)\n\ndf[\"misspelled_ratio\"] = df['text'].apply(lambda x: misspelledRatio(x))  \ntest[\"misspelled_ratio\"] = test['text'].apply(lambda x: misspelledRatio(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:03.268561Z","iopub.execute_input":"2023-09-14T13:03:03.269694Z","iopub.status.idle":"2023-09-14T13:03:05.111016Z","shell.execute_reply.started":"2023-09-14T13:03:03.269606Z","shell.execute_reply":"2023-09-14T13:03:05.109831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 3</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Stop word Ratio in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\ndef StopwordsRatio(context, response):\n    length  = len(response.split())\n    response = \" \".join([i for i in response.split() if i in stop_words]) \n    return len(response)/length\n\ndf[\"stop_word_ratio\"] = df.apply(lambda x: StopwordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"stop_word_ratio\"] = test.apply(lambda x: StopwordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.112657Z","iopub.execute_input":"2023-09-14T13:03:05.113088Z","iopub.status.idle":"2023-09-14T13:03:05.131989Z","shell.execute_reply.started":"2023-09-14T13:03:05.113058Z","shell.execute_reply":"2023-09-14T13:03:05.130812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 4</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Count of same words in Student's summary</h1></div>","metadata":{}},{"cell_type":"code","source":"def sameWordsRatio(context, response):\n    context = \" \".join([i for i in context.split() if i not in stop_words]) \n    response = \" \".join([i for i in response.split() if i not in stop_words]) \n    return len(set(response).intersection(set(context)))/len(response)\n\ndf[\"same_word_ratio\"] = df.apply(lambda x: sameWordsRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest[\"same_word_ratio\"] = test.apply(lambda x: sameWordsRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.135766Z","iopub.execute_input":"2023-09-14T13:03:05.136141Z","iopub.status.idle":"2023-09-14T13:03:05.181423Z","shell.execute_reply.started":"2023-09-14T13:03:05.136103Z","shell.execute_reply":"2023-09-14T13:03:05.179957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 5</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Average reading speed in words per minute </h1></div>","metadata":{}},{"cell_type":"code","source":"def readTime(x):\n    average_wpm = 200\n    word_count = len(x.split())\n    return word_count / average_wpm\n\ndf[\"read_time\"] = df['text'].apply(lambda x: readTime(x))  \ntest[\"read_time\"] = test['text'].apply(lambda x: readTime(x))  ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.182820Z","iopub.execute_input":"2023-09-14T13:03:05.183452Z","iopub.status.idle":"2023-09-14T13:03:05.193541Z","shell.execute_reply.started":"2023-09-14T13:03:05.183408Z","shell.execute_reply":"2023-09-14T13:03:05.192052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 6</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Diversity of words in the Student's response </h1></div>","metadata":{}},{"cell_type":"code","source":"def diversityIndex(x):\n    words = x.split()\n    word_counts = Counter(words)\n    total_words = len(words)\n    return 1 - sum((count / total_words) ** 2 for count in word_counts.values())\n\ndf[\"diversity_index\"] = df['text'].apply(lambda x: diversityIndex(x))  \ntest[\"diversity_index\"] = test['text'].apply(lambda x: diversityIndex(x))  ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.195015Z","iopub.execute_input":"2023-09-14T13:03:05.196067Z","iopub.status.idle":"2023-09-14T13:03:05.209304Z","shell.execute_reply.started":"2023-09-14T13:03:05.196022Z","shell.execute_reply":"2023-09-14T13:03:05.208466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 7</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> TF IDF to identify most frequent words in context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"def tfidfImportance(context, response):\n    top_n = 10\n\n    context = \" \".join([i for i in context.split() if i not in stop_words]) \n    response = \" \".join([i for i in response.split() if i not in stop_words]) \n    \n    corpus = [\n        context, response\n     ]\n\n    tfidf_unigram = TfidfVectorizer(ngram_range=(1, 1))\n    tfidf_unigram_matrix = tfidf_unigram.fit_transform(corpus)\n    unigram_feature_names = tfidf_unigram.get_feature_names_out()\n    dense_unigram_array = tfidf_unigram_matrix.toarray()\n    unigram_df = pd.DataFrame(data=dense_unigram_array, columns=unigram_feature_names)\n\n    top_unigrams = []\n    for index, row in unigram_df.iterrows():\n        top_unigrams.append(list(row.nlargest(top_n).index))\n\n    tfidf_bigram = TfidfVectorizer(ngram_range=(2, 2)) \n\n    tfidf_bigram_matrix = tfidf_bigram.fit_transform(corpus)\n    bigram_feature_names = tfidf_bigram.get_feature_names_out()\n    dense_bigram_array = tfidf_bigram_matrix.toarray()\n    bigram_df = pd.DataFrame(data=dense_bigram_array, columns=bigram_feature_names)\n\n    top_bigrams = []\n    for index, row in bigram_df.iterrows():\n        top_bigrams.append(list(row.nlargest(top_n).index))\n\n\n    return len(set(top_unigrams[0]).intersection(set(top_unigrams[1])))/top_n, len(set(top_bigrams[0]).intersection(set(top_bigrams[1])))/top_n\n\ndf[['top_unigrams_ratio','top_bigrams_ratio']]= df.apply(lambda x: tfidfImportance(x['prompt_text'], x['correct_text']), axis=1, result_type ='expand')\ntest[['top_unigrams_ratio','top_bigrams_ratio']]= test.apply(lambda x: tfidfImportance(x['prompt_text'], x['correct_text']), axis=1, result_type ='expand')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.211017Z","iopub.execute_input":"2023-09-14T13:03:05.211714Z","iopub.status.idle":"2023-09-14T13:03:05.544268Z","shell.execute_reply.started":"2023-09-14T13:03:05.211669Z","shell.execute_reply":"2023-09-14T13:03:05.543045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 8</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Cosine similarity of context and response using TD IDF vectors</h1></div>","metadata":{}},{"cell_type":"code","source":"def tdidfSimilarity(context, response):\n    vectorizer = TfidfVectorizer()\n    vectors = vectorizer.fit_transform([context, response])\n    return cosine_similarity(vectors[0:1], vectors[1:2])[0][0] \n\ndf['tfidf_similarity']= df.apply(lambda x: tdidfSimilarity(x['prompt_text'], x['correct_text']), axis=1)\ntest['tfidf_similarity']= test.apply(lambda x: tdidfSimilarity(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.545947Z","iopub.execute_input":"2023-09-14T13:03:05.546405Z","iopub.status.idle":"2023-09-14T13:03:05.661447Z","shell.execute_reply.started":"2023-09-14T13:03:05.546341Z","shell.execute_reply":"2023-09-14T13:03:05.660279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 9</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> N Grams Co occurence context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"def tokenize(sentence):\n    sentence = re.sub(r'[^\\w\\s]', '', sentence.lower())\n    tokens = sentence.split()\n    return tokens\n\ndef generate_ngrams(tokens, n):\n    ngrams = []\n    for i in range(len(tokens) - n + 1):\n        ngram = tuple(tokens[i:i + n])\n        ngrams.append(ngram)\n    return ngrams\n\n\ndef cooccurrenceRatio(context, response, n_gram_size = 2):\n    tokens1 = tokenize(context)\n    tokens2 = tokenize(response)\n\n    ngrams1 = generate_ngrams(tokens1, n_gram_size)\n    ngrams2 = generate_ngrams(tokens2, n_gram_size)\n\n    co_occurrence_count = len(set(ngrams1) & set(ngrams2))\n    \n    return co_occurrence_count/(min(len(ngrams1),len(ngrams2))+1)\n\ndf['bi_gram_ratio'] = df.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest['bi_gram_ratio'] = test.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\n\ndf['tri_gram_ratio'] = df.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text'], n_gram_size = 3), axis=1)\ntest['tri_gram_ratio'] = test.apply(lambda x: cooccurrenceRatio(x['prompt_text'], x['correct_text'],n_gram_size = 3 ), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.665307Z","iopub.execute_input":"2023-09-14T13:03:05.665817Z","iopub.status.idle":"2023-09-14T13:03:05.704232Z","shell.execute_reply.started":"2023-09-14T13:03:05.665685Z","shell.execute_reply":"2023-09-14T13:03:05.703137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 10</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Check punctuation in Student's response </h1></div>","metadata":{}},{"cell_type":"code","source":"def checkPunctuations(x):\n    punctuation_count = 0\n\n    for char in x:\n        if char in string.punctuation:\n            punctuation_count += 1\n    return punctuation_count/len(x.split())\n\ndf[\"punctuation_ratio\"] = df['text'].apply(lambda x: checkPunctuations(x))\ntest[\"punctuation_ratio\"] = test['text'].apply(lambda x: checkPunctuations(x)) ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.705811Z","iopub.execute_input":"2023-09-14T13:03:05.706265Z","iopub.status.idle":"2023-09-14T13:03:05.716255Z","shell.execute_reply.started":"2023-09-14T13:03:05.706223Z","shell.execute_reply":"2023-09-14T13:03:05.715054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div><h1 style=\"text-align: left; font-size: 25px;\"> üìç Feature 11</h1></div>\n<div><h1 style=\"text-align: left; font-size: 20px;\"> Identifying Co occurences of NER in context and response </h1></div>","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\n\ndef nerCooccurrenceRatio(context, response, n_gram_size = 2):\n    \n    doc1 = nlp(context)\n    doc2 = nlp(response)\n    \n    entities1 = {ent.text for ent in doc1.ents}\n    entities2 = {ent.text for ent in doc2.ents}\n    \n    overlap_entities = entities1.intersection(entities2)\n    return len(overlap_entities)/(min(len(entities1),len(entities2))+1)\n\n\ndf['nercooccurrence_ratio'] = df.apply(lambda x: nerCooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)\ntest['nercooccurrence_ratio'] = test.apply(lambda x: nerCooccurrenceRatio(x['prompt_text'], x['correct_text']), axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:05.718096Z","iopub.execute_input":"2023-09-14T13:03:05.718534Z","iopub.status.idle":"2023-09-14T13:03:09.120522Z","shell.execute_reply.started":"2023-09-14T13:03:05.718496Z","shell.execute_reply":"2023-09-14T13:03:09.119403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #b6d7a8; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üî¨ EDA ‚öóÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,2, 1)  \nsns.histplot(x=df['content'], bins=50, kde=True, color='#ed8240')\nplt.title(f\"Histogram of content\")\n\nplt.subplot(1,2, 2)  \nsns.histplot(x=df['wording'], bins=50, kde=True, color='#c540ed')\nplt.title(f\"Histogram of wording\")\n\nplt.tight_layout() \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:09.122086Z","iopub.execute_input":"2023-09-14T13:03:09.122465Z","iopub.status.idle":"2023-09-14T13:03:10.001312Z","shell.execute_reply.started":"2023-09-14T13:03:09.122433Z","shell.execute_reply":"2023-09-14T13:03:10.000190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = [\n    'word_count_ratio', \n    'misspelled_ratio', \n    'stop_word_ratio',\n    'same_word_ratio', \n    'read_time', \n    'diversity_index', \n    'top_unigrams_ratio',\n    'top_bigrams_ratio',\n    'tfidf_similarity',\n    'punctuation_ratio', \n    'bi_gram_ratio',\n    'tri_gram_ratio', \n    'nercooccurrence_ratio'\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:10.002734Z","iopub.execute_input":"2023-09-14T13:03:10.003069Z","iopub.status.idle":"2023-09-14T13:03:10.011252Z","shell.execute_reply.started":"2023-09-14T13:03:10.003031Z","shell.execute_reply":"2023-09-14T13:03:10.009842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cols = ['content','wording'] + cols\nplt.figure(figsize=(15, 7))\nsns.heatmap(df[all_cols].corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:10.013408Z","iopub.execute_input":"2023-09-14T13:03:10.013976Z","iopub.status.idle":"2023-09-14T13:03:11.126748Z","shell.execute_reply.started":"2023-09-14T13:03:10.013934Z","shell.execute_reply":"2023-09-14T13:03:11.125734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in cols:\n    print(f'Plots for {col}')\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1,3, 1)  \n    sns.scatterplot(x=df[col], y=df['content'], color='#4082ed')\n    plt.title(\"Scatterplot with content\")\n\n    plt.subplot(1, 3, 2)  \n    sns.scatterplot(x=df[col], y=df['wording'], color='#40b9ed')\n    plt.title(\"Scatterplot with wording\")\n\n    plt.subplot(1, 3, 3)  \n    sns.histplot(x=df[col], bins=50, kde=True, color='#40d3ed')\n    plt.title(f\"Histogram of {col}\")\n\n    plt.tight_layout() \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:11.128053Z","iopub.execute_input":"2023-09-14T13:03:11.128375Z","iopub.status.idle":"2023-09-14T13:03:23.844172Z","shell.execute_reply.started":"2023-09-14T13:03:11.128333Z","shell.execute_reply":"2023-09-14T13:03:23.842792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"background-color: #8dc1e9; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üê• Bert Embedding üê•</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"model_name = \"/kaggle/input/huggingface-bert/bert-base-uncased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\nmax_chunk_length = 512\n\n\ndef get_embeddings_for_sent(sent):\n    input_ids = tokenizer(sent, padding=True, truncation=True, max_length=max_chunk_length, return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs = model(**input_ids)\n    cls_embedding = outputs.last_hidden_state[:, 0, :] \n    return cls_embedding\n\n\ndef get_embeddings_for_para(document):\n    chunks = [document[i:i + max_chunk_length] for i in range(0, len(document), max_chunk_length)]\n    chunk_embeddings = []\n    for chunk in chunks:\n        input_ids = tokenizer(chunk, padding=True, truncation=True, max_length=max_chunk_length, return_tensors=\"pt\")\n        with torch.no_grad():\n            outputs = model(**input_ids)\n            cls_embedding = outputs.last_hidden_state[:, 0, :]\n        chunk_embeddings.append(cls_embedding)\n        final_embedding = torch.mean(torch.stack(chunk_embeddings), dim=0)\n        return final_embedding","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:23.845902Z","iopub.execute_input":"2023-09-14T13:03:23.846301Z","iopub.status.idle":"2023-09-14T13:03:25.646835Z","shell.execute_reply.started":"2023-09-14T13:03:23.846265Z","shell.execute_reply":"2023-09-14T13:03:25.645272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of prompt_question \nprmt_data = df[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\nprmt_test = test[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\n\nprmt_data[\"text_emb\"] = prmt_data['prompt_question'].apply(lambda x: get_embeddings_for_sent(x))  \nprmt_data[\"flattened_embedding\"] = prmt_data[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_df = pd.DataFrame(prmt_data[\"flattened_embedding\"].to_list())\nemb_df = pd.concat([prmt_data[['prompt_id']], emb_df],axis = 1)\nemb_df = df[['prompt_id']].merge(emb_df, on = 'prompt_id', how = 'left').drop(['prompt_id'], axis= 1)\n\nprmt_test[\"text_emb\"] = prmt_test['prompt_question'].apply(lambda x: get_embeddings_for_sent(x))  \nprmt_test[\"flattened_embedding\"] = prmt_test[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_test = pd.DataFrame(prmt_test[\"flattened_embedding\"].to_list())\nemb_test = pd.concat([prmt_test[['prompt_id']], emb_test],axis = 1)\nemb_test = test[['prompt_id']].merge(emb_test, on = 'prompt_id', how = 'left').drop(['prompt_id'],axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:25.648281Z","iopub.execute_input":"2023-09-14T13:03:25.649001Z","iopub.status.idle":"2023-09-14T13:03:25.886059Z","shell.execute_reply.started":"2023-09-14T13:03:25.648964Z","shell.execute_reply":"2023-09-14T13:03:25.884794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of prompt_text\nprmt_data = df[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\nprmt_test = test[['prompt_id','prompt_question','prompt_text']].drop_duplicates().reset_index(drop = True)\n\nprmt_data[\"text_emb\"] = prmt_data['prompt_text'].apply(lambda x: get_embeddings_for_para(x))  \nprmt_data[\"flattened_embedding\"] = prmt_data[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_cntxt_df = pd.DataFrame(prmt_data[\"flattened_embedding\"].to_list())\nemb_cntxt_df = pd.concat([prmt_data[['prompt_id']], emb_cntxt_df],axis = 1)\nemb_cntxt_df = df[['prompt_id']].merge(emb_cntxt_df, on = 'prompt_id', how = 'left').drop(['prompt_id'], axis= 1)\n\nprmt_test[\"text_emb\"] = prmt_test['prompt_text'].apply(lambda x: get_embeddings_for_para(x))  \nprmt_test[\"flattened_embedding\"] = prmt_test[\"text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_cntxt_test = pd.DataFrame(prmt_test[\"flattened_embedding\"].to_list())\nemb_cntxt_test = pd.concat([prmt_test[['prompt_id']], emb_cntxt_test],axis = 1)\nemb_cntxt_test = test[['prompt_id']].merge(emb_cntxt_test, on = 'prompt_id', how = 'left').drop(['prompt_id'],axis= 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:25.887485Z","iopub.execute_input":"2023-09-14T13:03:25.887840Z","iopub.status.idle":"2023-09-14T13:03:26.239582Z","shell.execute_reply.started":"2023-09-14T13:03:25.887808Z","shell.execute_reply":"2023-09-14T13:03:26.238451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding of response\ndf[\"correct_text_emb\"] = df['correct_text'].apply(lambda x: get_embeddings_for_sent(x))  \ndf[\"correct_text_flattened_embedding\"] = df[\"correct_text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_corrt_df = pd.DataFrame(df[\"correct_text_flattened_embedding\"].to_list())\n\ntest[\"correct_text_emb\"] = test['correct_text'].apply(lambda x: get_embeddings_for_sent(x))  \ntest[\"correct_text_flattened_embedding\"] = test[\"correct_text_emb\"].apply(lambda x: x.flatten().numpy())\nemb_corrt_test = pd.DataFrame(test[\"correct_text_flattened_embedding\"].to_list())","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:26.241019Z","iopub.execute_input":"2023-09-14T13:03:26.241485Z","iopub.status.idle":"2023-09-14T13:03:29.227118Z","shell.execute_reply.started":"2023-09-14T13:03:26.241440Z","shell.execute_reply":"2023-09-14T13:03:29.225857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df[cols]\ntest_score = test[cols]\nY = df[['content','wording']]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:29.231833Z","iopub.execute_input":"2023-09-14T13:03:29.232284Z","iopub.status.idle":"2023-09-14T13:03:29.241562Z","shell.execute_reply.started":"2023-09-14T13:03:29.232249Z","shell.execute_reply":"2023-09-14T13:03:29.240265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val = train_test_split(train, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:03:29.243547Z","iopub.execute_input":"2023-09-14T13:03:29.244061Z","iopub.status.idle":"2023-09-14T13:03:29.256646Z","shell.execute_reply.started":"2023-09-14T13:03:29.244017Z","shell.execute_reply":"2023-09-14T13:03:29.255579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_cntxt_train = emb_cntxt_df.filter(X_train.index, axis=0)\nemb_cntxt_val = emb_cntxt_df.filter(X_val.index, axis=0)\n\nemb_corrt_train = emb_corrt_df.filter(X_train.index, axis=0)\nemb_corrt_val = emb_corrt_df.filter(X_val.index, axis=0)\n\nemb_train = emb_df.filter(X_train.index, axis=0)\nemb_val = emb_df.filter(X_val.index, axis=0)\n\nY_train = Y.filter(X_train.index, axis=0)\nY_val = Y.filter(X_val.index, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:09.221288Z","iopub.execute_input":"2023-09-14T13:06:09.222301Z","iopub.status.idle":"2023-09-14T13:06:09.236001Z","shell.execute_reply.started":"2023-09-14T13:06:09.221987Z","shell.execute_reply":"2023-09-14T13:06:09.234665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_side_features = len(X_train.columns)\nhidden_dim1 = int(num_side_features/2)\nnum_emb= 768","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:10.629861Z","iopub.execute_input":"2023-09-14T13:06:10.630258Z","iopub.status.idle":"2023-09-14T13:06:10.635866Z","shell.execute_reply.started":"2023-09-14T13:06:10.630228Z","shell.execute_reply":"2023-09-14T13:06:10.634669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\nquestion_inputs_train = torch.from_numpy(emb_cntxt_train.to_numpy())\ncontext_inputs_train = torch.from_numpy(emb_train.to_numpy())\nresponse_inputs_train = torch.from_numpy(emb_corrt_train.to_numpy())\nside_feat_train = torch.from_numpy(X_train.to_numpy().astype(np.float32))\nY_train = torch.from_numpy(Y_train.to_numpy())\n\nquestion_inputs_val = torch.from_numpy(emb_cntxt_val.to_numpy())\ncontext_inputs_val = torch.from_numpy(emb_val.to_numpy())\nresponse_inputs_val = torch.from_numpy(emb_corrt_val.to_numpy())\nside_feat_val = torch.from_numpy(X_val.to_numpy().astype(np.float32))\nY_val = torch.from_numpy(Y_val.to_numpy())\n\nquestion_inputs_test = torch.from_numpy(emb_cntxt_test.to_numpy())\ncontext_inputs_test = torch.from_numpy(emb_test.to_numpy())\nresponse_inputs_test = torch.from_numpy(emb_corrt_test.to_numpy())\nside_feat_test = torch.from_numpy(test_score.to_numpy().astype(np.float32))\n\ndataset_tensor_train = TensorDataset(question_inputs_train, context_inputs_train, response_inputs_train, side_feat_train, Y_train)\ndataset_tensor_val = TensorDataset(question_inputs_val, context_inputs_val, response_inputs_val, side_feat_val, Y_val)\n\ntrain_loader = DataLoader(dataset_tensor_train, batch_size, shuffle=False)  \nval_loader = DataLoader(dataset_tensor_val, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:20.958614Z","iopub.execute_input":"2023-09-14T13:06:20.959017Z","iopub.status.idle":"2023-09-14T13:06:20.973170Z","shell.execute_reply.started":"2023-09-14T13:06:20.958986Z","shell.execute_reply":"2023-09-14T13:06:20.971847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #ffe599; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> üè≠ Deep learning Architecture üèóÔ∏è</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"# Define the deep learning model\nclass BertDotProductModel(nn.Module):\n    def __init__(self, num_emb, num_side_features, hidden_dim1):\n        super(BertDotProductModel, self).__init__()\n\n        self.side_feature_layer = nn.Linear(num_side_features, hidden_dim1)  \n        \n        self.fc1 = nn.Linear((num_emb * 2 + hidden_dim1 + 1), num_emb)\n        self.fc2 = nn.Linear(768, 512) \n        self.fc3 = nn.Linear(512, 512) \n        self.fc4 = nn.Linear(512, 256) \n        self.fc5 = nn.Linear(256, 128) \n        self.fc6 = nn.Linear(128, 64)\n        self.fc7 = nn.Linear(64, 2) \n        self.relu = torch.nn.ReLU()\n\n    def forward(self, question, context, response, side_features):\n\n        dot_product = torch.sum(context * response, dim=1)\n        side_features = self.side_feature_layer(side_features)\n        residual_context = torch.sub(question, context)\n        residual_response = torch.sub(question, response)\n        concat_features = torch.cat((dot_product.unsqueeze(1), residual_context, residual_response, side_features), dim=1)\n\n        fc_output = self.relu(concat_features)\n        fc_output = self.fc1(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc2(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc3(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc4(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc5(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc6(fc_output)\n        fc_output = self.relu(fc_output)\n        fc_output = self.fc7(fc_output)\n        \n        return fc_output","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:23.962152Z","iopub.execute_input":"2023-09-14T13:06:23.962571Z","iopub.status.idle":"2023-09-14T13:06:23.974216Z","shell.execute_reply.started":"2023-09-14T13:06:23.962536Z","shell.execute_reply":"2023-09-14T13:06:23.972874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertDotProductModel(num_emb, num_side_features, hidden_dim1)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:24.953425Z","iopub.execute_input":"2023-09-14T13:06:24.953807Z","iopub.status.idle":"2023-09-14T13:06:24.995621Z","shell.execute_reply.started":"2023-09-14T13:06:24.953778Z","shell.execute_reply":"2023-09-14T13:06:24.994586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss = []\nvalidation_loss = []\n\ncriterion = nn.MSELoss()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\nnum_epochs = 20\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0.0\n\n    for question, context, response, side_features, target in train_loader:\n        optimizer.zero_grad()\n        outputs = model(question, context, response, side_features)  \n    \n        target = target.to(torch.float)\n\n        loss1 = torch.sqrt(criterion(outputs[:, 0].squeeze(), target[:,0]))\n        loss2 = torch.sqrt(criterion(outputs[:, 1].squeeze(), target[:,1])) \n        \n        loss = loss1 + loss2\n        total_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    training_loss.append(total_loss / len(train_loader))\n\n    model.eval()\n    valid_loss = 0.0\n\n    with torch.no_grad():\n        for question, context, response, side_features, target in val_loader:\n            outputs = model(question, context, response, side_features)\n            loss1 = torch.sqrt(criterion(outputs[:, 0].squeeze(), target[:,0])) \n            loss2 = torch.sqrt(criterion(outputs[:, 1].squeeze(), target[:,1])) \n            \n            loss = loss1 + loss2 \n            \n            valid_loss += loss.item()\n            \n    validation_loss.append(valid_loss / len(val_loader))\n\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:48.986954Z","iopub.execute_input":"2023-09-14T13:06:48.987332Z","iopub.status.idle":"2023-09-14T13:06:49.403829Z","shell.execute_reply.started":"2023-09-14T13:06:48.987304Z","shell.execute_reply":"2023-09-14T13:06:49.402639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=[i for i in range(num_epochs)], y=training_loss)\nsns.lineplot(x=[i for i in range(num_epochs)], y=validation_loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:50.463048Z","iopub.execute_input":"2023-09-14T13:06:50.463470Z","iopub.status.idle":"2023-09-14T13:06:50.715938Z","shell.execute_reply.started":"2023-09-14T13:06:50.463434Z","shell.execute_reply":"2023-09-14T13:06:50.714641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nwith torch.no_grad():\n    outputs = model(question_inputs_test, context_inputs_test, response_inputs_test, side_feat_test)\n\noutputs = outputs.numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:52.482621Z","iopub.execute_input":"2023-09-14T13:06:52.483559Z","iopub.status.idle":"2023-09-14T13:06:52.492297Z","shell.execute_reply.started":"2023-09-14T13:06:52.483522Z","shell.execute_reply":"2023-09-14T13:06:52.491420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncontent_list = outputs[:, 0].tolist()\nwording_list = outputs[:, 1].tolist()\n\nsubmission = test[['student_id']]\nsubmission['content'] = content_list\nsubmission['wording'] = wording_list\n\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:06:53.378292Z","iopub.execute_input":"2023-09-14T13:06:53.378896Z","iopub.status.idle":"2023-09-14T13:06:53.397459Z","shell.execute_reply.started":"2023-09-14T13:06:53.378865Z","shell.execute_reply":"2023-09-14T13:06:53.396148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #bcbcbc; padding: 10px; border-radius: 15px;\">\n    <h1 style=\"text-align: center; font-size: 28px;\"> If you find it useful, please upvote for my efforts ‚¨ÜÔ∏è </h1>\n</div>","metadata":{}}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}